{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HW4 \u2013 Assignment 2\n",
        "\n",
        "This notebook trains logistic regression models on the `smarket.csv` data set and focuses on the Lag1/Lag2-only specification required in Assignment 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import csv\n",
        "import math\n",
        "from typing import List, Sequence, Tuple\n",
        "\n",
        "DATA_PATH = Path(\"smarket.csv\")\n",
        "FEATURE_NAMES = [f\"Lag{i}\" for i in range(1, 6)] + [\"Volume\"]\n",
        "\n",
        "def load_smarket(path: Path) -> Tuple[List[dict], List[int], List[int]]:\n",
        "    rows: List[dict] = []\n",
        "    labels: List[int] = []\n",
        "    years: List[int] = []\n",
        "    with path.open(newline=\"\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            years.append(int(row[\"Year\"]))\n",
        "            rows.append({name: float(row[name]) for name in FEATURE_NAMES})\n",
        "            labels.append(1 if row[\"Direction\"].strip().lower() == \"up\" else 0)\n",
        "    return rows, labels, years\n",
        "\n",
        "rows, labels, years = load_smarket(DATA_PATH)\n",
        "\n",
        "def split_by_year(selected_features: Sequence[str]):\n",
        "    train_X: List[List[float]] = []\n",
        "    train_y: List[int] = []\n",
        "    test_X: List[List[float]] = []\n",
        "    test_y: List[int] = []\n",
        "    for feat_row, label, year in zip(rows, labels, years):\n",
        "        vector = [feat_row[name] for name in selected_features]\n",
        "        if year < 2005:\n",
        "            train_X.append(vector)\n",
        "            train_y.append(label)\n",
        "        elif year == 2005:\n",
        "            test_X.append(vector)\n",
        "            test_y.append(label)\n",
        "    return train_X, train_y, test_X, test_y\n",
        "\n",
        "def compute_scaler(dataset: Sequence[Sequence[float]]):\n",
        "    n_features = len(dataset[0])\n",
        "    means = [sum(row[i] for row in dataset) / len(dataset) for i in range(n_features)]\n",
        "    stds: List[float] = []\n",
        "    for i in range(n_features):\n",
        "        mean_i = means[i]\n",
        "        variance = sum((row[i] - mean_i) ** 2 for row in dataset) / len(dataset)\n",
        "        stds.append(variance ** 0.5 if variance > 0 else 1.0)\n",
        "    return means, stds\n",
        "\n",
        "def apply_scaler(dataset: Sequence[Sequence[float]], means: Sequence[float], stds: Sequence[float]):\n",
        "    scaled: List[List[float]] = []\n",
        "    for row in dataset:\n",
        "        scaled.append([(row[i] - means[i]) / stds[i] for i in range(len(row))])\n",
        "    return scaled\n",
        "\n",
        "def add_bias(dataset: Sequence[Sequence[float]]):\n",
        "    return [[1.0] + list(row) for row in dataset]\n",
        "\n",
        "def sigmoid(z: float) -> float:\n",
        "    if z >= 0:\n",
        "        ez = math.exp(-z)\n",
        "        return 1.0 / (1.0 + ez)\n",
        "    ez = math.exp(z)\n",
        "    return ez / (1.0 + ez)\n",
        "\n",
        "def solve_linear_system(matrix: List[List[float]], vector: List[float]):\n",
        "    n = len(vector)\n",
        "    augmented = [row[:] + [vector[i]] for i, row in enumerate(matrix)]\n",
        "    for col in range(n):\n",
        "        pivot = max(range(col, n), key=lambda r: abs(augmented[r][col]))\n",
        "        if abs(augmented[pivot][col]) < 1e-12:\n",
        "            raise ValueError(\"Singular matrix encountered in Newton step\")\n",
        "        if pivot != col:\n",
        "            augmented[col], augmented[pivot] = augmented[pivot], augmented[col]\n",
        "        pivot_val = augmented[col][col]\n",
        "        augmented[col] = [val / pivot_val for val in augmented[col]]\n",
        "        for row in range(n):\n",
        "            if row == col:\n",
        "                continue\n",
        "            factor = augmented[row][col]\n",
        "            if factor == 0:\n",
        "                continue\n",
        "            augmented[row] = [augmented[row][i] - factor * augmented[col][i] for i in range(n + 1)]\n",
        "    return [augmented[i][-1] for i in range(n)]\n",
        "\n",
        "def train_logistic(features: Sequence[Sequence[float]], labels: Sequence[int], *, l2: float = 1e-3,\n",
        "                   max_iter: int = 30, tol: float = 1e-9):\n",
        "    n_features = len(features[0])\n",
        "    weights = [0.0] * n_features\n",
        "    for _ in range(max_iter):\n",
        "        gradient = [0.0] * n_features\n",
        "        hessian = [[0.0] * n_features for _ in range(n_features)]\n",
        "        for row, target in zip(features, labels):\n",
        "            z = sum(w * x for w, x in zip(weights, row))\n",
        "            p = sigmoid(z)\n",
        "            diff = p - target\n",
        "            for j in range(n_features):\n",
        "                gradient[j] += diff * row[j]\n",
        "            weight = p * (1.0 - p)\n",
        "            for i in range(n_features):\n",
        "                for j in range(n_features):\n",
        "                    hessian[i][j] += weight * row[i] * row[j]\n",
        "        for j in range(1, n_features):\n",
        "            gradient[j] += l2 * weights[j]\n",
        "            hessian[j][j] += l2\n",
        "        step = solve_linear_system(hessian, gradient)\n",
        "        max_delta = max(abs(delta) for delta in step)\n",
        "        weights = [w - delta for w, delta in zip(weights, step)]\n",
        "        if max_delta < tol:\n",
        "            break\n",
        "    return weights\n",
        "\n",
        "def predict_probabilities(features: Sequence[Sequence[float]], weights: Sequence[float]):\n",
        "    return [sigmoid(sum(w * x for w, x in zip(weights, row))) for row in features]\n",
        "\n",
        "def accuracy_from_probs(probs: Sequence[float], labels: Sequence[int], threshold: float = 0.5) -> float:\n",
        "    preds = [1 if prob >= threshold else 0 for prob in probs]\n",
        "    return sum(int(pred == target) for pred, target in zip(preds, labels)) / len(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Assignment 1 baseline: Lag1-Lag5 plus Volume\n",
        "X_train_all, y_train_all, X_test_all, y_test_all = split_by_year(FEATURE_NAMES)\n",
        "train_means_all, train_stds_all = compute_scaler(X_train_all)\n",
        "X_train_all_scaled = add_bias(apply_scaler(X_train_all, train_means_all, train_stds_all))\n",
        "X_test_all_scaled = add_bias(apply_scaler(X_test_all, train_means_all, train_stds_all))\n",
        "weights_all = train_logistic(X_train_all_scaled, y_train_all)\n",
        "probs_all = predict_probabilities(X_test_all_scaled, weights_all)\n",
        "acc_all = accuracy_from_probs(probs_all, y_test_all)\n",
        "print(f\"Assignment 1 \u2013 LR with Lag1-Lag5 & Volume accuracy: {acc_all:.3f}\")\n",
        "\n",
        "# Assignment 2 model: Lag1 and Lag2 only\n",
        "lag12_features = [\"Lag1\", \"Lag2\"]\n",
        "X_train_12, y_train_12, X_test_12, y_test_12 = split_by_year(lag12_features)\n",
        "train_means_12, train_stds_12 = compute_scaler(X_train_12)\n",
        "X_train_12_scaled = add_bias(apply_scaler(X_train_12, train_means_12, train_stds_12))\n",
        "X_test_12_scaled = add_bias(apply_scaler(X_test_12, train_means_12, train_stds_12))\n",
        "weights_12 = train_logistic(X_train_12_scaled, y_train_12)\n",
        "probs_12 = predict_probabilities(X_test_12_scaled, weights_12)\n",
        "acc_12 = accuracy_from_probs(probs_12, y_test_12)\n",
        "print(f\"Assignment 2 \u2013 LR with Lag1 & Lag2 accuracy: {acc_12:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Lag1/Lag2-only logistic regression attains higher accuracy than the Assignment 1 model with all six predictors, indicating that the additional lags and volume add noise for the 2005 test data rather than helpful signal."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}