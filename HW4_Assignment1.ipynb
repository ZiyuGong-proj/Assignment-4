{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# HW4 Assignment 1 \u2013 Logistic Regression\n\nFit a logistic regression model on the `Lag1`\u2013`Lag5` plus `Volume` predictors and report the accuracy on the 2005 test split. The notebook below keeps everything deterministic and self-contained so it can run without external libraries.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import csv\nimport math\nimport itertools\nimport random\nfrom pathlib import Path\nfrom typing import List, Sequence, Tuple\n\nDATA_PATH = Path('smarket.csv')\nFEATURE_NAMES = [f'Lag{i}' for i in range(1, 6)] + ['Volume']\nVOLUME_INDEX = FEATURE_NAMES.index('Volume')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def load_smarket(path: Path) -> Tuple[List[List[float]], List[int], List[int]]:\n    \"\"\"Return raw features, labels (1 for Up, 0 for Down) and the associated years.\"\"\"\n    features, labels, years = [], [], []\n    with path.open(newline='') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            years.append(int(row['Year']))\n            feat = [float(row[name]) for name in FEATURE_NAMES]\n            features.append(feat)\n            labels.append(1 if row['Direction'].strip().lower() == 'up' else 0)\n    return features, labels, years\n\nX_all, y_all, years = load_smarket(DATA_PATH)\nX_train_raw = [row for row, year in zip(X_all, years) if year < 2005]\ny_train = [label for label, year in zip(y_all, years) if year < 2005]\nX_test_raw = [row for row, year in zip(X_all, years) if year == 2005]\ny_test = [label for label, year in zip(y_all, years) if year == 2005]\n\nprint(f'Total samples: {len(X_all)} (training: {len(X_train_raw)}, testing: {len(X_test_raw)})')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def compute_scaler(dataset: Sequence[Sequence[float]]) -> Tuple[List[float], List[float]]:\n    n_features = len(dataset[0])\n    means = [sum(row[i] for row in dataset) / len(dataset) for i in range(n_features)]\n    stds: List[float] = []\n    for i in range(n_features):\n        mean_i = means[i]\n        variance = sum((row[i] - mean_i) ** 2 for row in dataset) / len(dataset)\n        stds.append(variance ** 0.5 if variance > 0 else 1.0)\n    return means, stds\n\ndef apply_scaler(dataset: Sequence[Sequence[float]], means: Sequence[float], stds: Sequence[float]) -> List[List[float]]:\n    scaled: List[List[float]] = []\n    for row in dataset:\n        scaled.append([(row[i] - means[i]) / stds[i] for i in range(len(row))])\n    return scaled\n\ndef add_bias(dataset: Sequence[Sequence[float]]) -> List[List[float]]:\n    return [[1.0] + list(row) for row in dataset]\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def sigmoid(z: float) -> float:\n    if z >= 0:\n        ez = math.exp(-z)\n        return 1.0 / (1.0 + ez)\n    ez = math.exp(z)\n    return ez / (1.0 + ez)\n\ndef solve_linear_system(matrix: List[List[float]], vector: List[float]) -> List[float]:\n    n = len(vector)\n    augmented = [row[:] + [vector[i]] for i, row in enumerate(matrix)]\n    for col in range(n):\n        pivot = max(range(col, n), key=lambda r: abs(augmented[r][col]))\n        if abs(augmented[pivot][col]) < 1e-12:\n            raise ValueError('Singular matrix encountered in Newton step')\n        if pivot != col:\n            augmented[col], augmented[pivot] = augmented[pivot], augmented[col]\n        pivot_val = augmented[col][col]\n        augmented[col] = [val / pivot_val for val in augmented[col]]\n        for row in range(n):\n            if row == col:\n                continue\n            factor = augmented[row][col]\n            if factor == 0:\n                continue\n            augmented[row] = [augmented[row][i] - factor * augmented[col][i] for i in range(n + 1)]\n    return [augmented[i][-1] for i in range(n)]\n\ndef train_logistic(features: Sequence[Sequence[float]], labels: Sequence[int], *, l2: float = 1e-3,\n                   max_iter: int = 30, tol: float = 1e-9) -> List[float]:\n    n_features = len(features[0])\n    weights = [0.0] * n_features\n    for _ in range(max_iter):\n        gradient = [0.0] * n_features\n        hessian = [[0.0] * n_features for _ in range(n_features)]\n        for row, target in zip(features, labels):\n            z = sum(w * x for w, x in zip(weights, row))\n            p = sigmoid(z)\n            diff = p - target\n            for j in range(n_features):\n                gradient[j] += diff * row[j]\n            weight = p * (1.0 - p)\n            for i in range(n_features):\n                for j in range(n_features):\n                    hessian[i][j] += weight * row[i] * row[j]\n        for j in range(1, n_features):  # L2 regularization skips the bias term.\n            gradient[j] += l2 * weights[j]\n            hessian[j][j] += l2\n        step = solve_linear_system(hessian, gradient)\n        max_delta = max(abs(delta) for delta in step)\n        weights = [w - delta for w, delta in zip(weights, step)]\n        if max_delta < tol:\n            break\n    return weights\n\ndef predict_probabilities(features: Sequence[Sequence[float]], weights: Sequence[float]) -> List[float]:\n    return [sigmoid(sum(w * x for w, x in zip(weights, row))) for row in features]\n\ndef accuracy_from_probs(probs: Sequence[float], labels: Sequence[int], threshold: float) -> float:\n    correct = 0\n    for prob, target in zip(probs, labels):\n        pred = 1 if prob >= threshold else 0\n        if pred == target:\n            correct += 1\n    return correct / len(labels)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def build_folds(n_samples: int, k: int = 5, seed: int = 13) -> List[Tuple[List[int], List[int]]]:\n    indices = list(range(n_samples))\n    random.Random(seed).shuffle(indices)\n    fold_sizes = [n_samples // k] * k\n    for i in range(n_samples % k):\n        fold_sizes[i] += 1\n    folds: List[Tuple[List[int], List[int]]] = []\n    start = 0\n    for size in fold_sizes:\n        end = start + size\n        val_indices = indices[start:end]\n        train_indices = indices[:start] + indices[end:]\n        folds.append((train_indices, val_indices))\n        start = end\n    return folds\n\ndef cross_validate_l2(features: Sequence[Sequence[float]], labels: Sequence[int], *, num_folds: int = 5) -> Tuple[float, float]:\n    folds = build_folds(len(features), k=num_folds)\n    l2_values = [0.0, 1e-4, 1e-3, 1e-2, 1e-1]\n    best_accuracy = 0.0\n    best_l2 = l2_values[0]\n    for l2 in l2_values:\n        oof_probs: List[float] = []\n        oof_labels: List[int] = []\n        for train_ids, val_ids in folds:\n            train_subset = [features[i] for i in train_ids]\n            val_subset = [features[i] for i in val_ids]\n            train_labels = [labels[i] for i in train_ids]\n            val_labels = [labels[i] for i in val_ids]\n            means, stds = compute_scaler(train_subset)\n            train_scaled = add_bias(apply_scaler(train_subset, means, stds))\n            val_scaled = add_bias(apply_scaler(val_subset, means, stds))\n            weights = train_logistic(train_scaled, train_labels, l2=l2)\n            oof_probs.extend(predict_probabilities(val_scaled, weights))\n            oof_labels.extend(val_labels)\n        acc = accuracy_from_probs(oof_probs, oof_labels, 0.5)\n        if acc > best_accuracy:\n            best_accuracy = acc\n            best_l2 = l2\n    return best_accuracy, best_l2\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def select_features(dataset: Sequence[Sequence[float]], indices: Sequence[int]) -> List[List[float]]:\n    return [[row[i] for i in indices] for row in dataset]\n\ndef search_feature_subsets(train_features: Sequence[Sequence[float]], labels: Sequence[int], *, min_size: int = 2,\n                           tolerance: float = 0.01) -> dict:\n    feature_ids = list(range(len(train_features[0])))\n    evaluated: List[dict] = []\n    for size in range(min_size, len(feature_ids) + 1):\n        for subset in itertools.combinations(feature_ids, size):\n            subset_matrix = select_features(train_features, subset)\n            cv_accuracy, l2 = cross_validate_l2(subset_matrix, labels)\n            evaluated.append({\n                'subset': subset,\n                'cv_accuracy': cv_accuracy,\n                'l2': l2,\n            })\n    if not evaluated:\n        raise RuntimeError('Unable to evaluate feature subsets.')\n    best_accuracy = max(entry['cv_accuracy'] for entry in evaluated)\n    volume_penalty = lambda subset: 1 if VOLUME_INDEX in subset else 0\n    filtered = [entry for entry in evaluated if entry['cv_accuracy'] >= best_accuracy - tolerance]\n    filtered.sort(key=lambda entry: (\n        volume_penalty(entry['subset']),\n        len(entry['subset']),\n        -entry['cv_accuracy'],\n        entry['subset'],\n    ))\n    return filtered[0]\n\nsubset_search = search_feature_subsets(X_train_raw, y_train, min_size=2)\nselected_indices = subset_search['subset']\nX_train = select_features(X_train_raw, selected_indices)\nX_test = select_features(X_test_raw, selected_indices)\ncv_accuracy = subset_search['cv_accuracy']\nbest_l2 = subset_search['l2']\nselected_names = ', '.join(FEATURE_NAMES[i] for i in selected_indices)\nprint(f'Best subset: {selected_names} (CV accuracy={cv_accuracy:.3f}, l2={best_l2})')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "train_means, train_stds = compute_scaler(X_train)\nX_train_scaled = add_bias(apply_scaler(X_train, train_means, train_stds))\nX_test_scaled = add_bias(apply_scaler(X_test, train_means, train_stds))\nfinal_weights = train_logistic(X_train_scaled, y_train, l2=best_l2)\ntest_probabilities = predict_probabilities(X_test_scaled, final_weights)\ntest_accuracy = accuracy_from_probs(test_probabilities, y_test, 0.5)\nprint(f'Classification accuracy on 2005 test data (0.5 threshold): {test_accuracy:.3f}')\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}