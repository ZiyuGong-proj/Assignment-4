{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# HW4 Assignments 1 & 2 \u2013 Logistic Regression\n\nFit logistic regression models on the `Lag1`\u2013`Lag5` plus `Volume` predictors (Assignment 1) and on the `Lag1`/`Lag2` subset (Assignment 2). Everything below remains deterministic and self-contained so the notebook can run without external machine-learning libraries.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import csv\nimport math\nimport itertools\nimport random\nfrom pathlib import Path\nfrom typing import List, Sequence, Tuple\n\nDATA_PATH = Path('smarket.csv')\nFEATURE_NAMES = [f'Lag{i}' for i in range(1, 6)] + ['Volume']\nVOLUME_INDEX = FEATURE_NAMES.index('Volume')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def load_smarket(path: Path) -> Tuple[List[List[float]], List[int], List[int]]:\n    \"\"\"Return raw features, labels (1 for Up, 0 for Down) and the associated years.\"\"\"\n    features, labels, years = [], [], []\n    with path.open(newline='') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            years.append(int(row['Year']))\n            feat = [float(row[name]) for name in FEATURE_NAMES]\n            features.append(feat)\n            labels.append(1 if row['Direction'].strip().lower() == 'up' else 0)\n    return features, labels, years\n\nX_all, y_all, years = load_smarket(DATA_PATH)\nX_train_raw = [row for row, year in zip(X_all, years) if year < 2005]\ny_train = [label for label, year in zip(y_all, years) if year < 2005]\nX_test_raw = [row for row, year in zip(X_all, years) if year == 2005]\ny_test = [label for label, year in zip(y_all, years) if year == 2005]\n\nprint(f'Total samples: {len(X_all)} (training: {len(X_train_raw)}, testing: {len(X_test_raw)})')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def compute_scaler(dataset: Sequence[Sequence[float]]) -> Tuple[List[float], List[float]]:\n    n_features = len(dataset[0])\n    means = [sum(row[i] for row in dataset) / len(dataset) for i in range(n_features)]\n    stds: List[float] = []\n    for i in range(n_features):\n        mean_i = means[i]\n        variance = sum((row[i] - mean_i) ** 2 for row in dataset) / len(dataset)\n        stds.append(variance ** 0.5 if variance > 0 else 1.0)\n    return means, stds\n\ndef apply_scaler(dataset: Sequence[Sequence[float]], means: Sequence[float], stds: Sequence[float]) -> List[List[float]]:\n    scaled: List[List[float]] = []\n    for row in dataset:\n        scaled.append([(row[i] - means[i]) / stds[i] for i in range(len(row))])\n    return scaled\n\ndef add_bias(dataset: Sequence[Sequence[float]]) -> List[List[float]]:\n    return [[1.0] + list(row) for row in dataset]\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def sigmoid(z: float) -> float:\n    if z >= 0:\n        ez = math.exp(-z)\n        return 1.0 / (1.0 + ez)\n    ez = math.exp(z)\n    return ez / (1.0 + ez)\n\ndef solve_linear_system(matrix: List[List[float]], vector: List[float]) -> List[float]:\n    n = len(vector)\n    augmented = [row[:] + [vector[i]] for i, row in enumerate(matrix)]\n    for col in range(n):\n        pivot = max(range(col, n), key=lambda r: abs(augmented[r][col]))\n        if abs(augmented[pivot][col]) < 1e-12:\n            raise ValueError('Singular matrix encountered in Newton step')\n        if pivot != col:\n            augmented[col], augmented[pivot] = augmented[pivot], augmented[col]\n        pivot_val = augmented[col][col]\n        augmented[col] = [val / pivot_val for val in augmented[col]]\n        for row in range(n):\n            if row == col:\n                continue\n            factor = augmented[row][col]\n            if factor == 0:\n                continue\n            augmented[row] = [augmented[row][i] - factor * augmented[col][i] for i in range(n + 1)]\n    return [augmented[i][-1] for i in range(n)]\n\ndef train_logistic(features: Sequence[Sequence[float]], labels: Sequence[int], *, l2: float = 1e-3,\n                   max_iter: int = 30, tol: float = 1e-9) -> List[float]:\n    n_features = len(features[0])\n    weights = [0.0] * n_features\n    for _ in range(max_iter):\n        gradient = [0.0] * n_features\n        hessian = [[0.0] * n_features for _ in range(n_features)]\n        for row, target in zip(features, labels):\n            z = sum(w * x for w, x in zip(weights, row))\n            p = sigmoid(z)\n            diff = p - target\n            for j in range(n_features):\n                gradient[j] += diff * row[j]\n            weight = p * (1.0 - p)\n            for i in range(n_features):\n                for j in range(n_features):\n                    hessian[i][j] += weight * row[i] * row[j]\n        for j in range(1, n_features):  # L2 regularization skips the bias term.\n            gradient[j] += l2 * weights[j]\n            hessian[j][j] += l2\n        step = solve_linear_system(hessian, gradient)\n        max_delta = max(abs(delta) for delta in step)\n        weights = [w - delta for w, delta in zip(weights, step)]\n        if max_delta < tol:\n            break\n    return weights\n\ndef predict_probabilities(features: Sequence[Sequence[float]], weights: Sequence[float]) -> List[float]:\n    return [sigmoid(sum(w * x for w, x in zip(weights, row))) for row in features]\n\ndef accuracy_from_probs(probs: Sequence[float], labels: Sequence[int], threshold: float) -> float:\n    correct = 0\n    for prob, target in zip(probs, labels):\n        pred = 1 if prob >= threshold else 0\n        if pred == target:\n            correct += 1\n    return correct / len(labels)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def build_folds(n_samples: int, k: int = 5, seed: int = 13) -> List[Tuple[List[int], List[int]]]:\n    indices = list(range(n_samples))\n    random.Random(seed).shuffle(indices)\n    fold_sizes = [n_samples // k] * k\n    for i in range(n_samples % k):\n        fold_sizes[i] += 1\n    folds: List[Tuple[List[int], List[int]]] = []\n    start = 0\n    for size in fold_sizes:\n        end = start + size\n        val_indices = indices[start:end]\n        train_indices = indices[:start] + indices[end:]\n        folds.append((train_indices, val_indices))\n        start = end\n    return folds\n\ndef cross_validate_l2(features: Sequence[Sequence[float]], labels: Sequence[int], *, num_folds: int = 5) -> Tuple[float, float]:\n    folds = build_folds(len(features), k=num_folds)\n    l2_values = [0.0, 1e-4, 1e-3, 1e-2, 1e-1]\n    best_accuracy = 0.0\n    best_l2 = l2_values[0]\n    for l2 in l2_values:\n        oof_probs: List[float] = []\n        oof_labels: List[int] = []\n        for train_ids, val_ids in folds:\n            train_subset = [features[i] for i in train_ids]\n            val_subset = [features[i] for i in val_ids]\n            train_labels = [labels[i] for i in train_ids]\n            val_labels = [labels[i] for i in val_ids]\n            means, stds = compute_scaler(train_subset)\n            train_scaled = add_bias(apply_scaler(train_subset, means, stds))\n            val_scaled = add_bias(apply_scaler(val_subset, means, stds))\n            weights = train_logistic(train_scaled, train_labels, l2=l2)\n            oof_probs.extend(predict_probabilities(val_scaled, weights))\n            oof_labels.extend(val_labels)\n        acc = accuracy_from_probs(oof_probs, oof_labels, 0.5)\n        if acc > best_accuracy:\n            best_accuracy = acc\n            best_l2 = l2\n    return best_accuracy, best_l2\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def select_features(dataset: Sequence[Sequence[float]], indices: Sequence[int]) -> List[List[float]]:\n    return [[row[i] for i in indices] for row in dataset]\n\n\ndef evaluate_feature_subset(feature_indices: Sequence[int], description: str, threshold: float = 0.5) -> dict:\n    X_train_subset = select_features(X_train_raw, feature_indices)\n    X_test_subset = select_features(X_test_raw, feature_indices)\n    cv_accuracy, l2 = cross_validate_l2(X_train_subset, y_train)\n    train_means, train_stds = compute_scaler(X_train_subset)\n    X_train_scaled = add_bias(apply_scaler(X_train_subset, train_means, train_stds))\n    X_test_scaled = add_bias(apply_scaler(X_test_subset, train_means, train_stds))\n    weights = train_logistic(X_train_scaled, y_train, l2=l2)\n    test_probabilities = predict_probabilities(X_test_scaled, weights)\n    test_accuracy = accuracy_from_probs(test_probabilities, y_test, threshold)\n    feature_names = ', '.join(FEATURE_NAMES[i] for i in feature_indices)\n    print(description)\n    print(f\"  Features: {feature_names}\")\n    print(f\"  Cross-validated accuracy: {cv_accuracy:.3f} (best l2={l2})\")\n    print(f\"  2005 test accuracy (threshold={threshold}): {test_accuracy:.3f}\")\n    print()\n    return {\n        'feature_indices': feature_indices,\n        'cv_accuracy': cv_accuracy,\n        'test_accuracy': test_accuracy,\n        'l2': l2,\n    }\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "assignment1 = evaluate_feature_subset(\n    list(range(len(FEATURE_NAMES))),\n    'Assignment 1: Lag1\u2013Lag5 plus Volume logistic regression'\n)\n\nassignment2 = evaluate_feature_subset(\n    [FEATURE_NAMES.index('Lag1'), FEATURE_NAMES.index('Lag2')],\n    'Assignment 2: Lag1 & Lag2 logistic regression'\n)\n\nassignment_summary = {\n    'Assignment 1 test accuracy': assignment1['test_accuracy'],\n    'Assignment 2 test accuracy': assignment2['test_accuracy'],\n}\nprint('Summary:', assignment_summary)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Assignment 2 discussion\n\nAssignment 1's full Lag1\u2013Lag5 plus Volume model achieved a 0.480 test accuracy, whereas Assignment 2's Lag1/Lag2-only model reached 0.560. The simpler classifier performs better because the two-lag subset avoids the multicollinearity and noise introduced by the additional lags and Volume. With only 998 training days, those extra predictors add variance without appreciably improving the signal, so the larger model overfits and its coefficients do not generalize as well to 2005. Restricting the LR to the most predictive lags keeps the fit stable and delivers the higher out-of-sample accuracy reported above.\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}