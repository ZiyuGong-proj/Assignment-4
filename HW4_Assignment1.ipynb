{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HW 4 \u2013 Assignment 1\n",
        "\n",
        "This notebook follows the instructions from **HW 4** to train a logistic regression model on the `smarket.csv` dataset. The goal is to use the historical market indicators `Lag1`-`Lag5` along with `Volume` to predict whether the market direction (`Direction`) will be **Up** or **Down** on the following day. Training is performed on records with `Year < 2005` and the 2005 data is reserved for testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import math\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = Path('smarket.csv')\n",
        "\n",
        "\n",
        "def load_smarket(path: Path):\n",
        "    \"\"\"Return features, labels, and years from the CSV file.\"\"\"\n",
        "    X, y, years = [], [], []\n",
        "    with path.open(newline='') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            years.append(int(row['Year']))\n",
        "            features = [float(row[f'Lag{i}']) for i in range(1, 6)]\n",
        "            features.append(float(row['Volume']))\n",
        "            X.append(features)\n",
        "            y.append(1 if row['Direction'].strip().lower() == 'up' else 0)\n",
        "    return X, y, years\n",
        "\n",
        "\n",
        "X, y, years = load_smarket(DATA_PATH)\n",
        "train_mask = [year < 2005 for year in years]\n",
        "test_mask = [year == 2005 for year in years]\n",
        "\n",
        "X_train = [x for x, keep in zip(X, train_mask) if keep]\n",
        "y_train = [label for label, keep in zip(y, train_mask) if keep]\n",
        "X_test = [x for x, keep in zip(X, test_mask) if keep]\n",
        "y_test = [label for label, keep in zip(y, test_mask) if keep]\n",
        "\n",
        "print(f\"Loaded {len(X)} total observations: {len(X_train)} for training and {len(X_test)} for testing.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_standardization(dataset):\n",
        "    n_features = len(dataset[0])\n",
        "    means = [sum(row[i] for row in dataset) / len(dataset) for i in range(n_features)]\n",
        "    stds = []\n",
        "    for i in range(n_features):\n",
        "        mean_i = means[i]\n",
        "        variance = sum((row[i] - mean_i) ** 2 for row in dataset) / len(dataset)\n",
        "        stds.append(variance ** 0.5 if variance > 0 else 1.0)\n",
        "    return means, stds\n",
        "\n",
        "\n",
        "def apply_standardization(dataset, means, stds):\n",
        "    scaled = []\n",
        "    for row in dataset:\n",
        "        scaled.append([(row[i] - means[i]) / stds[i] for i in range(len(row))])\n",
        "    return scaled\n",
        "\n",
        "\n",
        "feature_means, feature_stds = compute_standardization(X_train)\n",
        "X_train_scaled = apply_standardization(X_train, feature_means, feature_stds)\n",
        "X_test_scaled = apply_standardization(X_test, feature_means, feature_stds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid(z: float) -> float:\n",
        "    if z >= 0:\n",
        "        ez = math.exp(-z)\n",
        "        return 1.0 / (1.0 + ez)\n",
        "    ez = math.exp(z)\n",
        "    return ez / (1.0 + ez)\n",
        "\n",
        "\n",
        "def train_logistic_regression(features, labels, lr=0.1, epochs=2000):\n",
        "    n_features = len(features[0])\n",
        "    weights = [0.0] * (n_features + 1)\n",
        "    n_samples = len(features)\n",
        "    for epoch in range(epochs):\n",
        "        gradient = [0.0] * (n_features + 1)\n",
        "        for row, target in zip(features, labels):\n",
        "            z = weights[0]\n",
        "            for w, value in zip(weights[1:], row):\n",
        "                z += w * value\n",
        "            prediction = sigmoid(z)\n",
        "            error = prediction - target\n",
        "            gradient[0] += error\n",
        "            for j in range(n_features):\n",
        "                gradient[j + 1] += error * row[j]\n",
        "        step = lr / n_samples\n",
        "        for j in range(n_features + 1):\n",
        "            weights[j] -= step * gradient[j]\n",
        "    return weights\n",
        "\n",
        "\n",
        "def predict_classes(features, weights):\n",
        "    preds = []\n",
        "    for row in features:\n",
        "        score = weights[0]\n",
        "        for w, value in zip(weights[1:], row):\n",
        "            score += w * value\n",
        "        preds.append(1 if sigmoid(score) >= 0.5 else 0)\n",
        "    return preds\n",
        "\n",
        "\n",
        "weights = train_logistic_regression(X_train_scaled, y_train)\n",
        "predictions = predict_classes(X_test_scaled, weights)\n",
        "accuracy = sum(1 for pred, true in zip(predictions, y_test) if pred == true) / len(y_test)\n",
        "print(f\"Classification accuracy on 2005 test data: {accuracy:.3f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}